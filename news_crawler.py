import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse, parse_qs


def get_stock_news(stock_code, count=5):
    url = f"https://finance.naver.com/item/main.naver?code={stock_code}"
    headers = {
        "User-Agent": "Mozilla/5.0"
    }

    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")

    # ìµœì‹  ë‰´ìŠ¤ ì˜ì—­ í¬ë¡¤ë§
    news_tags = soup.select("div.section.new_bbs ul li span.txt > a")

    news_list = []

    # ì˜ˆì¸¡ ê¸°ëŠ¥ ì¹´ìš´íŠ¸
    ho_count = 0
    ak_count = 0

    for tag in news_tags:
        title = tag.get_text(strip=True)
        href = tag.get("href", "")
        if not title or "ê´€ë ¨" in title:
            continue
        full_url = "https://finance.naver.com" + href

        # ë‰´ìŠ¤ ê°ì„± ë¶„ë¥˜
        result, confidence = request_prediction(title)
        if result == "í˜¸ì¬":
            ho_count += 1
        elif result == "ì•…ì¬":
            ak_count += 1

        news_list.append(f"ğŸ“° [{title}]({full_url})â†’ {result}")
        if len(news_list) >= count:
            break
    if ho_count > ak_count:
        summary = "ğŸŸ¢ ì˜¤ëŠ˜ ë‰´ìŠ¤ ìš”ì•½: **í˜¸ì¬ ê²½í–¥**"
    elif ak_count > ho_count:
        summary = "ğŸ”´ ì˜¤ëŠ˜ ë‰´ìŠ¤ ìš”ì•½: **ì•…ì¬ ê²½í–¥**"
    else:
        summary = "âšªï¸ ì˜¤ëŠ˜ ë‰´ìŠ¤ ìš”ì•½: **íŒë‹¨ ìœ ë³´ (ë™ë¥ )**"

    news_list.append("")
    news_list.append(f"ğŸŸ¢ í˜¸ì¬ {ho_count}ê°œ")
    news_list.append(f"ğŸ”´ ì•…ì¬ {ak_count}ê°œ")
    news_list.append(summary)

    return news_list if news_list else ["âŒ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."]

def normalize_naver_url(href):
    """ìƒëŒ€ ê²½ë¡œ URLì„ ì •ê·œ ë„¤ì´ë²„ ë‰´ìŠ¤ URLë¡œ ë³€í™˜"""
    parsed = urlparse(href)
    qs = parse_qs(parsed.query)
    article_id = qs.get("article_id", [""])[0]
    office_id = qs.get("office_id", [""])[0]

    if article_id and office_id:
        return f"https://n.news.naver.com/mnews/article/{office_id}/{article_id}"
    return None

def get_main_news():
    url = "https://finance.naver.com/news/"
    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")

    news_list = []

    # ë‰´ìŠ¤ ëª©ë¡ì—ì„œ ìƒìœ„ 5ê°œ ì¶”ì¶œ
    for a in soup.select("div.main_news li a")[:5]:
        title = a.get_text(strip=True)
        href = a.get("href")
        if href and title:
            if href.startswith("http"):
                news_list.append(f"ğŸ“° [{title}]({href})")
            else:
                normalized = normalize_naver_url(href)
                if normalized:
                    news_list.append(f"ğŸ“° [{title}]({normalized})")

    return news_list if news_list else ["âŒ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."]

def request_prediction(text):
    url = "https://2ff8-211-213-33-230.ngrok-free.app/predict"
    payload = {"text": text}
    try:
        response = requests.post(url, json=payload)
        result=response.json()
        return result["result"], result["confidence"]
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")  # ì½˜ì†”ì— ì˜¤ë¥˜ ì´ìœ  ì¶œë ¥
        return "ì˜¤ë¥˜", 0
